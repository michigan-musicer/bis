## The interviewee sample is not representative of UofM 

By far the biggest issue, which I will break down into several components. See [demographics](/methodology_demographics) for more.

### There is overrepresentation of straight Asian or Caucasian men in engineering

I wouldn't say that all of their stories are the exact same (because they're not), but certain trends (e.g. heavy courseloads, having high-quality education prior to UofM) show up in this project that I don't think are necessarily trends across the entire student population. If a few stories feel same-y, this may be the reason why.

### There is underrepresentation of women, non-Asian or Caucasian ethnicites, and low GPAs

I don't think the expectation when doing a broad survey is to have perfect equality, as that may run into the issue of overrepresenting a group that really isn't that prominent. That being said, 7 out of 35 respondents to the demographic survey identified as women. This is 20% of the interviewee population at a university that has roughly a 50-50 split when classifying undergraduate student genders as male/female (see [this data report](https://diversity.umich.edu/data-reports/) from Michigan's DEI office here). This very clearly underrepresents a significant portion of the student population. 

(On an unrelated note, it doesn't seem that the DEI office has a chart taking into account non-binary students. Therefore I don't know what a "good" ballpark would be for number of respondents there; but seeing as to how there are no survey respondents reporting as non-binary, this project obviously lacks that perspective.)

African Americans / black students are a smaller group at the University of Michigan. Looking at undergraduates only, only 5% of the student population is African American / black, according to [this page](https://diversity.umich.edu/data-reports/) from the university's DEI office. We actually get a pretty close percentage at 6% of the demographic survey respondents stating they are African American / black; however, this is just 2 people. 

Even though we've hit the ballpark in raw percentage for African American / black students, it's unlikely that 2 stories can represent the entirety of their experience with BIS. I would argue that there's probably a minimum absolute number of interviews, barring percentages, that you would need to get something close to a broad view of a particular group's overall experience. In other words, it's not wise to take these two interviewees' stories and extrapolate that directly to the whole of the African American / black experience.

I do not know how North African or Middle Eastern students are counted by UofM. I believe that typically, if there's no field for ththeseis specific ethnicities, [they are classified as white](https://www.npr.org/2022/02/17/1079181478/us-census-middle-eastern-white-north-african-mena). Either way, I only have two respondents of this ethnicity, leading to the same problems as above.

GPAs are relatively high in this sample, with the lowest GPA being a 3.2. I do not know of there being public info about average GPAs at the university, but I imagine it is significantly lower than the average of the sample (3.75).

### Some groups are completely unrepresented

These groups include veterans; Latinx, native American / Amerindian, and Pacific islander ethnicities; nonbinary individuals; and transgender individuals. 

Because their stories are completely absent, readers who are from those groups may feel even more isolated reading the results of this project - the exact opposite effect that I'm looking for. This is exacerbated by the absence of BIS-related details that come up specific to these groups' stories - which, because I don't have interviews from these groups, I can't do much to remedy. 

## The questions are surface-level

There's nothing wrong with a surface-level probe of BIS, and I think it's a good call to start so that stories remain relatable to a broader audience. That said, raises more in-depth questions. For example: ? How will these stories change in 5 or 10 years as these individuals move further into the working world? How do demographics not represented at all in this sample (see above) fare with BIS? Those questions that get raised aren't really answerable by the information in this project.

The biggest gripe I have with the questions is that instead of asking something like "How severely do you believe you were impacted by burnout and/or imposter syndrome?", the questions were "Have you experienced burnout and/or imposter syndrome?". A yes/no answer tells you less than the *degree* of the problem. In particular, what a student may report as burnout or imposter syndrome could just be a normal level of post-work tiredness or unsureness.

## The project was made by one person

I am proud of what I've done, but the project wore me down a lot, and my work became rustier towards the end of development. I could have been more disciplined and more productive, but even if I were more diligent, it's still exhausting to work on this while working a 9-to-5 job (I did not take a weekend off for more than two months). Exhaustion affects quality, and you will probably see typos and other mistakes that wouldn't have shown up if I was "fresh" when I was working on that specific thing. 

In the future - and for anyone considering something similar - it would be a lot better to work with a small team. If transcription and editing takes 100 hours, two people can halve that to 50 hours each. Four people can divide it into 25 hours each. I think it still requires a significant sacrifice of personal time or a fairly long project timetable (which, personally speaking, is its own stressor), so try to find others who are committed to putting in that time.

## The person making the project was inexperienced

Interviewing by itself I did not that difficult (although because many of the interviewees are close connections, some were mentally or emotionally exhausting). However, I only got into "the flow" of transcription in the last five or so interviews I transcribed, and even then I was probably taking 1.5x the length of each recording (which were an average of 40 minutes each) to transcribe. When I was starting, a single transcription could take three or four days. An experienced transcriber with a foot pedal can take as long or shorter than the recording time to complete a task; these time savings could have been spent on polish or figuring out other issues that popped up with the project.

I am not a particularly good web dev either, so the website implementation is not the best. In particular, the viewing experience on mobile may have some issues. I'll be keeping an eye out for any critical issues as this project gets released.

A proper research project mentored by a competent advisor should obviously have higher quality and depth of methodology, results, and observations than this project. Not to say that this project is useless, but a lack of experience *does* detract from the project's potential positive impact.